Loading data done.....
funcMatMul: 342 milliseconds
funcRELU: 1427 milliseconds
funcXNORMaxPool: 489 milliseconds
funcMatMul: 123 milliseconds
funcRELU: 542 milliseconds
funcXNORMaxPool: 327 milliseconds
funcMatMul: 90 milliseconds
funcRELU: 305 milliseconds
funcMatMul: 13 milliseconds
funcRELU: 283 milliseconds
MPC Output over uint32_t:

----------------------------------------------
Wall Clock time for LeNet test: 4.08688 sec
CPU time for LeNet test: 1.1227 sec
----------------------------------------------
----------------------------------------------
Total communication: 78.4704MB (sent) and 78.4704MB (recv)
Total calls: 162 (sends) and 162 (recvs)
----------------------------------------------
----------------------------------------------
Communication, LeNet test, P0: 26.1568MB (sent) 26.1568MB (recv)
Rounds, LeNet test, P0: 54(sends) 54(recvs)
----------------------------------------------
----------------------------------------------
Run details: 3PC (P0), 1 iterations, batch size 64
Running Semi-honest LeNet test on MNIST dataset
----------------------------------------------

----------------------------------------------
(1) CNN Layer		  28 x 28 x 1
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  64		(Batch Size)
			  24 x 24 x 20 	(Output)
----------------------------------------------
(2) ReLU Layer		  11520 x 64
----------------------------------------------
(3) Maxpool Layer	  24 x 24 x 20
			  2  		(Pooling Size)
			  2 		(Stride)
			  64		(Batch Size)
----------------------------------------------
(4) CNN Layer		  12 x 12 x 20
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  64		(Batch Size)
			  8 x 8 x 50 	(Output)
----------------------------------------------
(5) ReLU Layer		  3200 x 64
----------------------------------------------
(6) Maxpool Layer	  8 x 8 x 50
			  2  		(Pooling Size)
			  2 		(Stride)
			  64		(Batch Size)
----------------------------------------------
(7) FC Layer		  800 x 500
			  64		 (Batch Size)
----------------------------------------------
(8) ReLU Layer		  500 x 64
----------------------------------------------
(9) FC Layer		  500 x 10
			  64		 (Batch Size)
----------------------------------------------
(10) ReLU Layer		  10 x 64
----------------------------------------------
