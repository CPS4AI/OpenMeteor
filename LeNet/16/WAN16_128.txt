Loading data done.....
funcMatMul: 616 milliseconds
funcRELU: 2805 milliseconds
funcXNORMaxPool: 787 milliseconds
funcMatMul: 350 milliseconds
funcRELU: 867 milliseconds
funcXNORMaxPool: 381 milliseconds
funcMatMul: 87 milliseconds
funcRELU: 335 milliseconds
funcMatMul: 72 milliseconds
funcRELU: 284 milliseconds
MPC Output over uint32_t:

----------------------------------------------
Wall Clock time for LeNet test: 6.74233 sec
CPU time for LeNet test: 2.0099 sec
----------------------------------------------
----------------------------------------------
Total communication: 156.941MB (sent) and 156.941MB (recv)
Total calls: 162 (sends) and 162 (recvs)
----------------------------------------------
----------------------------------------------
Communication, LeNet test, P0: 52.3136MB (sent) 52.3136MB (recv)
Rounds, LeNet test, P0: 54(sends) 54(recvs)
----------------------------------------------
----------------------------------------------
Run details: 3PC (P0), 1 iterations, batch size 128
Running Semi-honest LeNet test on MNIST dataset
----------------------------------------------

----------------------------------------------
(1) CNN Layer		  28 x 28 x 1
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  128		(Batch Size)
			  24 x 24 x 20 	(Output)
----------------------------------------------
(2) ReLU Layer		  11520 x 128
----------------------------------------------
(3) Maxpool Layer	  24 x 24 x 20
			  2  		(Pooling Size)
			  2 		(Stride)
			  128		(Batch Size)
----------------------------------------------
(4) CNN Layer		  12 x 12 x 20
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  128		(Batch Size)
			  8 x 8 x 50 	(Output)
----------------------------------------------
(5) ReLU Layer		  3200 x 128
----------------------------------------------
(6) Maxpool Layer	  8 x 8 x 50
			  2  		(Pooling Size)
			  2 		(Stride)
			  128		(Batch Size)
----------------------------------------------
(7) FC Layer		  800 x 500
			  128		 (Batch Size)
----------------------------------------------
(8) ReLU Layer		  500 x 128
----------------------------------------------
(9) FC Layer		  500 x 10
			  128		 (Batch Size)
----------------------------------------------
(10) ReLU Layer		  10 x 128
----------------------------------------------
