Loading data done.....
funcMatMul: 344 milliseconds
funcRELU: 519 milliseconds
funcXNORMaxPool: 326 milliseconds
funcMatMul: 35 milliseconds
funcRELU: 330 milliseconds
funcXNORMaxPool: 291 milliseconds
funcMatMul: 64 milliseconds
funcRELU: 287 milliseconds
funcMatMul: 62 milliseconds
funcRELU: 285 milliseconds
MPC Output over uint32_t:

----------------------------------------------
Wall Clock time for LeNet test: 2.60548 sec
CPU time for LeNet test: 0.408125 sec
----------------------------------------------
----------------------------------------------
Total communication: 19.6176MB (sent) and 19.6176MB (recv)
Total calls: 162 (sends) and 162 (recvs)
----------------------------------------------
----------------------------------------------
Communication, LeNet test, P0: 6.5392MB (sent) 6.5392MB (recv)
Rounds, LeNet test, P0: 54(sends) 54(recvs)
----------------------------------------------
----------------------------------------------
Run details: 3PC (P0), 1 iterations, batch size 16
Running Semi-honest LeNet test on MNIST dataset
----------------------------------------------

----------------------------------------------
(1) CNN Layer		  28 x 28 x 1
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  16		(Batch Size)
			  24 x 24 x 20 	(Output)
----------------------------------------------
(2) ReLU Layer		  11520 x 16
----------------------------------------------
(3) Maxpool Layer	  24 x 24 x 20
			  2  		(Pooling Size)
			  2 		(Stride)
			  16		(Batch Size)
----------------------------------------------
(4) CNN Layer		  12 x 12 x 20
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  16		(Batch Size)
			  8 x 8 x 50 	(Output)
----------------------------------------------
(5) ReLU Layer		  3200 x 16
----------------------------------------------
(6) Maxpool Layer	  8 x 8 x 50
			  2  		(Pooling Size)
			  2 		(Stride)
			  16		(Batch Size)
----------------------------------------------
(7) FC Layer		  800 x 500
			  16		 (Batch Size)
----------------------------------------------
(8) ReLU Layer		  500 x 16
----------------------------------------------
(9) FC Layer		  500 x 10
			  16		 (Batch Size)
----------------------------------------------
(10) ReLU Layer		  10 x 16
----------------------------------------------
