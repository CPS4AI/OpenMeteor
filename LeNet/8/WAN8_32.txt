Loading data done.....
funcMatMul: 323 milliseconds
funcRELU: 564 milliseconds
funcXNORMaxPool: 275 milliseconds
funcMatMul: 84 milliseconds
funcRELU: 347 milliseconds
funcXNORMaxPool: 245 milliseconds
funcMatMul: 45 milliseconds
funcRELU: 272 milliseconds
funcMatMul: 37 milliseconds
funcRELU: 227 milliseconds
MPC Output over uint32_t:

----------------------------------------------
Wall Clock time for LeNet test: 2.54595 sec
CPU time for LeNet test: 0.484963 sec
----------------------------------------------
----------------------------------------------
Total communication: 21.433MB (sent) and 21.433MB (recv)
Total calls: 144 (sends) and 144 (recvs)
----------------------------------------------
----------------------------------------------
Communication, LeNet test, P0: 7.14432MB (sent) 7.14432MB (recv)
Rounds, LeNet test, P0: 48(sends) 48(recvs)
----------------------------------------------
----------------------------------------------
Run details: 3PC (P0), 1 iterations, batch size 32
Running Semi-honest LeNet test on MNIST dataset
----------------------------------------------

----------------------------------------------
(1) CNN Layer		  28 x 28 x 1
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  32		(Batch Size)
			  24 x 24 x 20 	(Output)
----------------------------------------------
(2) ReLU Layer		  11520 x 32
----------------------------------------------
(3) Maxpool Layer	  24 x 24 x 20
			  2  		(Pooling Size)
			  2 		(Stride)
			  32		(Batch Size)
----------------------------------------------
(4) CNN Layer		  12 x 12 x 20
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  32		(Batch Size)
			  8 x 8 x 50 	(Output)
----------------------------------------------
(5) ReLU Layer		  3200 x 32
----------------------------------------------
(6) Maxpool Layer	  8 x 8 x 50
			  2  		(Pooling Size)
			  2 		(Stride)
			  32		(Batch Size)
----------------------------------------------
(7) FC Layer		  800 x 500
			  32		 (Batch Size)
----------------------------------------------
(8) ReLU Layer		  500 x 32
----------------------------------------------
(9) FC Layer		  500 x 10
			  32		 (Batch Size)
----------------------------------------------
(10) ReLU Layer		  10 x 32
----------------------------------------------
