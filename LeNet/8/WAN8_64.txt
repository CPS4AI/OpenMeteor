Loading data done.....
funcMatMul: 388 milliseconds
funcRELU: 810 milliseconds
funcXNORMaxPool: 337 milliseconds
funcMatMul: 177 milliseconds
funcRELU: 346 milliseconds
funcXNORMaxPool: 255 milliseconds
funcMatMul: 107 milliseconds
funcRELU: 249 milliseconds
funcMatMul: 25 milliseconds
funcRELU: 270 milliseconds
MPC Output over uint32_t:

----------------------------------------------
Wall Clock time for LeNet test: 3.08242 sec
CPU time for LeNet test: 0.763665 sec
----------------------------------------------
----------------------------------------------
Total communication: 42.8659MB (sent) and 42.8659MB (recv)
Total calls: 144 (sends) and 144 (recvs)
----------------------------------------------
----------------------------------------------
Communication, LeNet test, P0: 14.2886MB (sent) 14.2886MB (recv)
Rounds, LeNet test, P0: 48(sends) 48(recvs)
----------------------------------------------
----------------------------------------------
Run details: 3PC (P0), 1 iterations, batch size 64
Running Semi-honest LeNet test on MNIST dataset
----------------------------------------------

----------------------------------------------
(1) CNN Layer		  28 x 28 x 1
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  64		(Batch Size)
			  24 x 24 x 20 	(Output)
----------------------------------------------
(2) ReLU Layer		  11520 x 64
----------------------------------------------
(3) Maxpool Layer	  24 x 24 x 20
			  2  		(Pooling Size)
			  2 		(Stride)
			  64		(Batch Size)
----------------------------------------------
(4) CNN Layer		  12 x 12 x 20
			  5 x 5  	(Filter Size)
			  1 , 0 	(Stride, padding)
			  64		(Batch Size)
			  8 x 8 x 50 	(Output)
----------------------------------------------
(5) ReLU Layer		  3200 x 64
----------------------------------------------
(6) Maxpool Layer	  8 x 8 x 50
			  2  		(Pooling Size)
			  2 		(Stride)
			  64		(Batch Size)
----------------------------------------------
(7) FC Layer		  800 x 500
			  64		 (Batch Size)
----------------------------------------------
(8) ReLU Layer		  500 x 64
----------------------------------------------
(9) FC Layer		  500 x 10
			  64		 (Batch Size)
----------------------------------------------
(10) ReLU Layer		  10 x 64
----------------------------------------------
